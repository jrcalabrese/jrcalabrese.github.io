---
title: "PSYCH 7823 Cheatsheet"
author:
  - name: Julianna Calabrese 
    url: https://jrcalabrese.github.io/
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    highlight_downlit: false
    highlight: tango
    toc: true
    number_sections: true
    toc_depth: 4
    smooth_scroll: true
    code_folding: true
---

```{r include=FALSE}
library(tidyverse)
library(sjPlot)
library(lme4)
data(mtcars)
set.seed(123)
```

# Introduction

## Symbols

| Symbol         | Mean        | Symbol         | Meaning                        |     |     |
| :------------- | :---------- | :------------- | :----------------------------- | :-- | :-- |
| $\beta_{0}$    | Intercept   | $\sigma$       | Variance                       |     |     |
| $\beta_{1}$    | Slope       | $\sigma^2$     | Standard deviation             |     |     |
| $\epsilon_{i}$ | Error       | $x_{1}$        | Sample statistic               |     |     |
| $\hat{y}$      | Estimate    | $x'_{1}$       | Mean-centered sample statistic |     |     |
| $\bar{y}$      | Average     | $\mu$          | Population parameter           |     |     |
| $N$            | Sample size | $N \sim (0,1)$ | Population distribution        |     |     |

| Symbol          | Meaning                                                                                     |
| :-------------- | :------------------------------------------------------------------------------------------ |
| $i$             | Individual or case (Level-1)                                                                |
| $j$             | Group or cluster (where $j$ = 1, ..., $J$; Level-2)                                         |
| $\gamma_00$     | Fixed intercept and the grand mean, i.e., the overall average value of $\bar{y}$            |
| $\upsilon_{0j}$ | Between-group variability: the deviation of group $j$ from the overall average $\gamma_00$. |
| $\epsilon_{ij}$ | Within-group variability: the case residual (within-group).                                 |
| $\tau_{00}$     | Variance of the Level-2 random intercepts                                                   |
| $\sigma^2$      | Variance of the Level-1 random intercepts                                                   |
| $\beta_{0j}$    | Random intercept                                                                            |
| $\beta_{1j}$    | Random slope                                                                                |

## Diagrams



# Regression

Independent variables: $x_1$, $x_2$, $x_3$, ...

Dependent variable: $Y$

## Intercept only

$$
\LARGE \operatorname{Y_{i}} = \beta_{0} + \epsilon_{i}
$$

```{r class.source="bg-danger", class.output="bg-warning"}
m1 <- lm(mpg ~ 1, mtcars)
tab_model(m1, 
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t",
          dv.labels = "Intercept Only")
```

## Simple linear regression

$$
\LARGE \operatorname{Y_{i}} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}
$$

```{r}
m2 <- lm(mpg ~ hp, mtcars)
tab_model(m2,           
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t",
          dv.labels = "Simple linear regression")
```

## Simple linear regresion with mean-centered x

$$
\LARGE \operatorname{Y_{i}} = \beta_{0} + \beta_{1}x'_{i} + \epsilon_{i}
$$

```{r}
mtcars$hp_c <- scale(mtcars$hp, center=TRUE, scale=FALSE) 
m3 <- lm(mpg ~ hp_c, mtcars)
tab_model(m3,           
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t",
          dv.labels = "Simple linear regression with mean-centered x")
```

## Multiple linear regression

$$
\LARGE {\operatorname{Y_{i}} = \beta_{0} + \beta_{1}x_1{i} + \beta_{2}x_2{i} + \epsilon_{i}}
$$

```{r}
m4 <- lm(mpg ~ hp + qsec, mtcars)
tab_model(m4, 
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t",
          dv.labels = "Multiple linear regression")
```

## Interaction / Moderation

$$
\LARGE \hat{\operatorname{Y}} = \hat{\beta}_{0} + \hat{\beta}_{1}x_1 + \hat{\beta}_{2}x_2 + \hat{\beta}_{3}x_1x_2
$$

Also can be written as:

$$
\LARGE \hat{\operatorname{Y}} = \hat{\beta}_{0} + \hat{\beta}_{1}x_1 + (\hat{\beta}_{2} + \hat{\beta}_{3}x_1)x_2 + \epsilon_{i}
$$

```{r}
m5 <- lm(mpg ~ hp + qsec + hp:qsec, mtcars)
tab_model(m5, 
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t", 
          dv.labels = "Moderated regression")
```

The effect of one predictor depends on the level of the other predictor, i.e., the effect of one predictor is *moderated* by the level of the other predictor.

$x_1$ is the focal predictor and $x_2$ is the moderating variable.

# Nested data

## Fixed effects model

$$ 
\LARGE \operatorname{Y_{i}} = {\beta}_{1}x_{1i} + {\beta}_{2}x_{2i} + ... + {\beta}_{p}x_{pi} + \epsilon_{i}
$$
$$
\LARGE \epsilon_{i} \sim_{iid} N(0, \sigma^2)
$$

```{r}
# m6 <- ???
# idk how to do this in R...
```

## Random effects ANOVA

Level-1:
$$ 
\LARGE \operatorname{Y_{ij}} = \beta_{0j} + \epsilon_{ij}
$$
$$
\LARGE \epsilon_{i} \sim N(0, \sigma^2)
$$

Level-2:
$$ 
\LARGE \operatorname{\beta_{0j}} = \gamma_{00} + \upsilon_{0j}
$$
$$
\LARGE \upsilon_{0j} \sim_{iid} N(0, \tau_{00})
$$

Reduced:
$$ 
\LARGE \operatorname{Y_{ij}} = \gamma_{00} + \upsilon_{0j} + \epsilon_{ij}
$$

```{r}
data(sleepstudy)
m7 <- lme4::lmer(Reaction ~ 1 + (1|Subject), sleepstudy)
tab_model(m7,           
          show.ci = FALSE, show.se = TRUE, show.stat = TRUE,
          string.intercept = "Intercept", string.se = "SE", string.stat = "t", 
          dv.labels = "Random effects ANOVA")
```

Also known as a one-way random effects model.

The Level-1 equation is a model for within-group differences, whereas the Level-2 equation is a model for between-group differences.

The *fixed effects* of the model are constant for all cases in the population and do not carry $i$ or $j$ subscripts. The Greek symbol gamma ($\gamma$) denotes these effects.

The *random effects* of the model vary across Level-1 and Level-2 units. Effects that vary across Level-2 units are denoted by $u$; effects that vary across Level-1 units are denoted by $\epsilon$.

## Random intercept regression model

Level-1:
$$ 
\LARGE \operatorname{Y_{ij}} = \beta_{0j} + \beta_{1j}x_{ij} + \epsilon_{ij}
$$
$$
\LARGE \epsilon_{i} \sim N(0, \sigma^2)
$$

Level-2:
$$ 
\LARGE \operatorname{\beta_{0j}} = \gamma_{00} + \upsilon_{0j}
$$
$$
\LARGE \operatorname{\beta_{1j}} = \gamma_{10}
$$
$$
\LARGE \upsilon_{0j} \sim_{iid} N(0, \tau_{00})
$$

Reduced:
$$ 
\LARGE \operatorname{Y_{ij}} = \gamma_{00} + \gamma_{10}x_{ij} + \upsilon_{0j} + \epsilon_{ij}
$$

```{r}
#m8 <- ??
```

$x_{ij}$ is a Level-1 predictor because it varies between group $j$ and case $i$. This model has four parameters:

* A fixed intercept, $\gamma_{00}$
* A fixed effect of $x_{ij}$, $\gamma_{10}$
* Residual variance of the Level-2 random intercepts, $\tau_{00}$
* Residual variance at Level-1, $\sigma^2$

The fixed effects are $\gamma_{00}$ and $\gamma_{10}$. The random effect is $\tau_{00}$. The covariance parameters are $\tau_{00}$ and $\sigma^2$. 

## Means as outcomes

Level-1:
$$ 
\LARGE \operatorname{Y_{ij}} = \beta_{0j} + \epsilon_{ij}
$$
$$
\LARGE \epsilon_{i} \sim N(0, \sigma^2)
$$

Level-2:
$$ 
\LARGE \operatorname{\beta_{0j}} = \gamma_{00} + \gamma_{01}w_{j} + \upsilon_{0j}
$$
$$
\LARGE \upsilon_{0j} \sim_{iid} N(0, \tau_{00})
$$

Reduced:
$$ 
\LARGE \operatorname{Y_{ij}} = \gamma_{00} + \gamma_{01}w_{j} + \upsilon_{0j} + \epsilon_{ij}
$$

Here, we incorporate Level-2 predictors to the random effects ANOVA model.

In a means as outcomes model, the means $\beta_{0j}$ are predicted with at least one Level-2 variable, $w$. Level-2 variables are literally *cluster means*, and the model
regresses $\beta_{0j}$ onto these means.

The fixed effects are $\gamma_{00}$ and $\gamma_{01}$. The random effect is $\tau_{00}$. The covariance parameters are $\tau_{00}$ and $\sigma^2$. 

## Intercepts as outcomes

Level-1:
$$ 
\LARGE \operatorname{Y_{ij}} = \beta_{0j} + \beta_{1j}x_{ij} + \epsilon_{ij}
$$
$$
\LARGE \epsilon_{i} \sim N(0, \sigma^2)
$$

Level-2:
$$ 
\LARGE \operatorname{\beta_{0j}} = \gamma_{00} + \gamma_{01}w_{j} + \upsilon_{0j}
$$
$$
\LARGE \operatorname{\beta_{1j}} = \gamma_{10}
$$
$$
\LARGE \upsilon_{0j} \sim_{iid} N(0, \tau_{00})
$$

Reduced:
$$ 
\LARGE \operatorname{Y_{ij}} = \gamma_{00} + \gamma_{01}w_{j} + \gamma_{10}x_{ij} + \upsilon_{0j} + \epsilon_{ij}
$$


Here, we incorporate Level-2 predictors to the random intercepts regression model. The random intercepts $\beta_{0j}$ are predictor with at least one Level-2 variable $w$.

The fixed effects are $\gamma_{00}$ and $\gamma_{10}$. The random effect is $\tau_{00}$. The covariance parameters are $\tau_{00}$ and $\sigma^2$. 
